{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebf11210",
   "metadata": {},
   "source": [
    "# Pyspark task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e15ca57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import types \n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3cf7a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+--------+---------+---------------------+-----+-------------------------+---------+----------+-------------+\n",
      "|Date      |Name of State / UT|Latitude|Longitude|Total Confirmed cases|Death|Cured/Discharged/Migrated|New cases|New deaths|New recovered|\n",
      "+----------+------------------+--------+---------+---------------------+-----+-------------------------+---------+----------+-------------+\n",
      "|2020-01-30|Kerala            |10.8505 |76.2711  |1.0                  |0    |0.0                      |0        |0         |0            |\n",
      "|2020-01-31|Kerala            |10.8505 |76.2711  |1.0                  |0    |0.0                      |0        |0         |0            |\n",
      "|2020-02-01|Kerala            |10.8505 |76.2711  |2.0                  |0    |0.0                      |1        |0         |0            |\n",
      "|2020-02-02|Kerala            |10.8505 |76.2711  |3.0                  |0    |0.0                      |1        |0         |0            |\n",
      "|2020-02-03|Kerala            |10.8505 |76.2711  |3.0                  |0    |0.0                      |0        |0         |0            |\n",
      "|2020-02-04|Kerala            |10.8505 |76.2711  |3.0                  |0    |0.0                      |0        |0         |0            |\n",
      "|2020-02-05|Kerala            |10.8505 |76.2711  |3.0                  |0    |0.0                      |0        |0         |0            |\n",
      "|2020-02-06|Kerala            |10.8505 |76.2711  |3.0                  |0    |0.0                      |0        |0         |0            |\n",
      "|2020-02-07|Kerala            |10.8505 |76.2711  |3.0                  |0    |0.0                      |0        |0         |0            |\n",
      "|2020-02-08|Kerala            |10.8505 |76.2711  |3.0                  |0    |0.0                      |0        |0         |0            |\n",
      "|2020-02-09|Kerala            |10.8505 |76.2711  |3.0                  |0    |0.0                      |0        |0         |0            |\n",
      "|2020-02-10|Kerala            |10.8505 |76.2711  |3.0                  |0    |0.0                      |0        |0         |0            |\n",
      "|2020-02-11|Kerala            |10.8505 |76.2711  |3.0                  |0    |0.0                      |0        |0         |0            |\n",
      "|2020-02-12|Kerala            |10.8505 |76.2711  |3.0                  |0    |0.0                      |0        |0         |0            |\n",
      "|2020-02-13|Kerala            |10.8505 |76.2711  |3.0                  |0    |0.0                      |0        |0         |0            |\n",
      "|2020-02-14|Kerala            |10.8505 |76.2711  |3.0                  |0    |0.0                      |0        |0         |0            |\n",
      "|2020-02-15|Kerala            |10.8505 |76.2711  |3.0                  |0    |0.0                      |0        |0         |0            |\n",
      "|2020-02-16|Kerala            |10.8505 |76.2711  |3.0                  |0    |0.0                      |0        |0         |0            |\n",
      "|2020-02-17|Kerala            |10.8505 |76.2711  |3.0                  |0    |0.0                      |0        |0         |0            |\n",
      "|2020-02-18|Kerala            |10.8505 |76.2711  |3.0                  |0    |0.0                      |0        |0         |0            |\n",
      "+----------+------------------+--------+---------+---------------------+-----+-------------------------+---------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"covid\").getOrCreate()\n",
    "filepath = \"complete.csv\"\n",
    "\n",
    "df_csv = spark.read.format(\"csv\") \\\n",
    "            .option(\"header\", True) \\\n",
    "            .option(\"multiLine\", True) \\\n",
    "            .option(\"ignoreLeadingWhiteSpace\",True) \\\n",
    "            .option(\"ignoreTrailingWhiteSpace\",True) \\\n",
    "            .option(\"escape\", \"\\\\\") \\\n",
    "            .option(\"quote\", \"\\\"\") \\\n",
    "            .load(filepath)\n",
    "\n",
    "# Print the first few rows of the DataFrame\n",
    "df_csv.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7afa07c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- Name of State / UT: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- Total Confirmed cases: string (nullable = true)\n",
      " |-- Death: string (nullable = true)\n",
      " |-- Cured/Discharged/Migrated: string (nullable = true)\n",
      " |-- New cases: string (nullable = true)\n",
      " |-- New deaths: string (nullable = true)\n",
      " |-- New recovered: string (nullable = true)\n",
      " |-- total_case: long (nullable = true)\n",
      " |-- total_newly_recovered: long (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- death_Case: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert necessary columns to appropriate types\n",
    "df_csv = df_csv.withColumn(\"total_case\", df_csv[\"Total Confirmed cases\"].cast(\"long\"))\n",
    "df_csv = df_csv.withColumn(\"total_newly_recovered\", df_csv[\"New recovered\"].cast(\"long\"))\n",
    "df_csv = df_csv.withColumn(\"state\", F.lower(df_csv[\"Name of State / UT\"]))\n",
    "df_csv = df_csv.withColumn(\"death_Case\", df_csv[\"Death\"].cast(\"long\"))\n",
    "df_csv = df_csv.withColumn(\"date\", F.to_date(df_csv[\"Date\"], \"yyyy-MM-dd\"))\n",
    "\n",
    "# Convert month number to name\n",
    "month_names = {\n",
    "    1: \"January\", 2: \"February\", 3: \"March\", 4: \"April\", 5: \"May\", 6: \"June\",\n",
    "    7: \"July\", 8: \"August\", 9: \"September\", 10: \"October\", 11: \"November\", 12: \"December\"\n",
    "}\n",
    "\n",
    "df_csv.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86702c5",
   "metadata": {},
   "source": [
    "# Task1: Convert state names to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90a76d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+\n",
      "|state                                   |\n",
      "+----------------------------------------+\n",
      "|delhi                                   |\n",
      "|maharashtra                             |\n",
      "|meghalaya                               |\n",
      "|odisha                                  |\n",
      "|haryana                                 |\n",
      "|west bengal                             |\n",
      "|goa                                     |\n",
      "|punjab                                  |\n",
      "|jammu and kashmir                       |\n",
      "|dadra and nagar haveli and daman and diu|\n",
      "|karnataka                               |\n",
      "|andhra pradesh                          |\n",
      "|telangana                               |\n",
      "|nagaland                                |\n",
      "|bihar                                   |\n",
      "|madhya pradesh                          |\n",
      "|jharkhand                               |\n",
      "|assam                                   |\n",
      "|kerala                                  |\n",
      "|tamil nadu                              |\n",
      "+----------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv = df_csv.withColumn(\"state\", F.lower(df_csv[\"Name of State / UT\"]))\n",
    "df_csv.select(\"state\").distinct().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84432785",
   "metadata": {},
   "source": [
    "# Task 2: Find the day with the greatest number of COVID cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c73324ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day with the greatest number of COVID cases: 2020-08-06 with 1964536 cases\n"
     ]
    }
   ],
   "source": [
    "daily_cases = df_csv.groupBy(\"date\").agg(F.sum(\"total_case\").alias(\"total_cases\"))\n",
    "day_max_cases = daily_cases.orderBy(F.desc(\"total_cases\")).first()\n",
    "day_max_cases_date = day_max_cases[\"date\"]\n",
    "day_max_cases_total = day_max_cases[\"total_cases\"]\n",
    "print(f\"Day with the greatest number of COVID cases: {day_max_cases_date} with {day_max_cases_total} cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8997a728",
   "metadata": {},
   "source": [
    "# Task 3: Find the state with the second-largest number of COVID cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c7201d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State with the second-largest number of COVID cases: tamil nadu with 7847083 cases\n"
     ]
    }
   ],
   "source": [
    "state_cases = df_csv.groupBy(\"state\").agg(F.sum(\"total_case\").alias(\"total_cases\"))\n",
    "second_largest_state = state_cases.orderBy(F.desc(\"total_cases\")).collect()[1]\n",
    "second_largest_state_name = second_largest_state[\"state\"]\n",
    "second_largest_state_total = second_largest_state[\"total_cases\"]\n",
    "print(f\"State with the second-largest number of COVID cases: {second_largest_state_name} with {second_largest_state_total} cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c3ec6f",
   "metadata": {},
   "source": [
    "# Task 4: Find the Union Territory with the least number of deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64ae418e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Union Territory with the least number of deaths: andaman and nicobar islands with 64 deaths\n"
     ]
    }
   ],
   "source": [
    "# Assuming a list of Union Territories\n",
    "union_territories = [\"delhi\", \"puducherry\", \"chandigarh\", \"andaman and nicobar islands\"]\n",
    "ut_deaths = df_csv.filter(F.col(\"state\").isin(union_territories)) \\\n",
    "                   .groupBy(\"state\") \\\n",
    "                   .agg(F.sum(\"death_Case\").alias(\"total_deaths\"))\n",
    "min_deaths_ut = ut_deaths.orderBy(F.asc(\"total_deaths\")).first()\n",
    "min_deaths_ut_name = min_deaths_ut[\"state\"]\n",
    "min_deaths_ut_total = min_deaths_ut[\"total_deaths\"]\n",
    "print(f\"Union Territory with the least number of deaths: {min_deaths_ut_name} with {min_deaths_ut_total} deaths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52401daa",
   "metadata": {},
   "source": [
    "# Task 5: Find the state with the lowest Death to Total Confirmed cases ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "260f1917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State with the lowest Death to Total Confirmed cases ratio: union territory of jammu and kashmir with a ratio of 0.0\n"
     ]
    }
   ],
   "source": [
    "state_ratios = df_csv.groupBy(\"state\") \\\n",
    "                     .agg((F.sum(\"death_Case\") / F.sum(\"total_case\")).alias(\"death_ratio\"))\n",
    "lowest_ratio_state = state_ratios.orderBy(F.asc(\"death_ratio\")).first()\n",
    "lowest_ratio_state_name = lowest_ratio_state[\"state\"]\n",
    "lowest_ratio_state_ratio = lowest_ratio_state[\"death_ratio\"]\n",
    "print(f\"State with the lowest Death to Total Confirmed cases ratio: {lowest_ratio_state_name} with a ratio of {lowest_ratio_state_ratio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951ed894",
   "metadata": {},
   "source": [
    "# Task 6: Find the month with the most New Recovered cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98c3ee05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month with the most new recovered cases: July with 722983 cases\n"
     ]
    }
   ],
   "source": [
    "df_csv = df_csv.withColumn(\"month\", F.month(df_csv[\"date\"]))\n",
    "monthly_recovered = df_csv.groupBy(\"month\").agg(F.sum(\"total_newly_recovered\").alias(\"total_new_recovered\"))\n",
    "max_recovered_month = monthly_recovered.orderBy(F.desc(\"total_new_recovered\")).first()\n",
    "max_recovered_month_number = max_recovered_month[\"month\"]\n",
    "max_recovered_month_total = max_recovered_month[\"total_new_recovered\"]\n",
    "max_recovered_month_name = month_names[max_recovered_month_number]\n",
    "print(f\"Month with the most new recovered cases: {max_recovered_month_name} with {max_recovered_month_total} cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f30415f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month with the most new recovered cases: July with 722983 cases\n"
     ]
    }
   ],
   "source": [
    "df_csv = df_csv.withColumn(\"month\", F.month(df_csv[\"date\"]))\n",
    "monthly_recovered = df_csv.groupBy(\"month\").agg(F.sum(\"total_newly_recovered\").alias(\"total_new_recovered\"))\n",
    "max_recovered_month = monthly_recovered.orderBy(F.desc(\"total_new_recovered\")).first()\n",
    "max_recovered_month_number = max_recovered_month[\"month\"]\n",
    "max_recovered_month_total = max_recovered_month[\"total_new_recovered\"]\n",
    "max_recovered_month_name = month_names[max_recovered_month_number]\n",
    "print(f\"Month with the most new recovered cases: {max_recovered_month_name} with {max_recovered_month_total} cases\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
